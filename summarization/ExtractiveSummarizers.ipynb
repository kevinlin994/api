{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\RobertPagano\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt') # one time execution\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/medium_articles.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>claps</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Justin Lee</td>\n",
       "      <td>8.3K</td>\n",
       "      <td>11</td>\n",
       "      <td>https://medium.com/swlh/chatbots-were-the-next...</td>\n",
       "      <td>Chatbots were the next big thing: what happene...</td>\n",
       "      <td>Oh, how the headlines blared:\\nChatbots were T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Conor Dewey</td>\n",
       "      <td>1.4K</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/python-for-data...</td>\n",
       "      <td>Python for Data Science: 8 Concepts You May Ha...</td>\n",
       "      <td>If you’ve ever found yourself looking up the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>William Koehrsen</td>\n",
       "      <td>2.8K</td>\n",
       "      <td>11</td>\n",
       "      <td>https://towardsdatascience.com/automated-featu...</td>\n",
       "      <td>Automated Feature Engineering in Python – Towa...</td>\n",
       "      <td>Machine learning is increasingly moving from h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gant Laborde</td>\n",
       "      <td>1.3K</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.freecodecamp.org/machine-learni...</td>\n",
       "      <td>Machine Learning: how to go from Zero to Hero ...</td>\n",
       "      <td>If your understanding of A.I. and Machine Lear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emmanuel Ameisen</td>\n",
       "      <td>935</td>\n",
       "      <td>11</td>\n",
       "      <td>https://blog.insightdatascience.com/reinforcem...</td>\n",
       "      <td>Reinforcement Learning from scratch – Insight ...</td>\n",
       "      <td>Want to learn about applied Artificial Intelli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author claps  reading_time  \\\n",
       "0        Justin Lee  8.3K            11   \n",
       "1       Conor Dewey  1.4K             7   \n",
       "2  William Koehrsen  2.8K            11   \n",
       "3      Gant Laborde  1.3K             7   \n",
       "4  Emmanuel Ameisen   935            11   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://medium.com/swlh/chatbots-were-the-next...   \n",
       "1  https://towardsdatascience.com/python-for-data...   \n",
       "2  https://towardsdatascience.com/automated-featu...   \n",
       "3  https://medium.freecodecamp.org/machine-learni...   \n",
       "4  https://blog.insightdatascience.com/reinforcem...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Chatbots were the next big thing: what happene...   \n",
       "1  Python for Data Science: 8 Concepts You May Ha...   \n",
       "2  Automated Feature Engineering in Python – Towa...   \n",
       "3  Machine Learning: how to go from Zero to Hero ...   \n",
       "4  Reinforcement Learning from scratch – Insight ...   \n",
       "\n",
       "                                                text  \n",
       "0  Oh, how the headlines blared:\\nChatbots were T...  \n",
       "1  If you’ve ever found yourself looking up the s...  \n",
       "2  Machine learning is increasingly moving from h...  \n",
       "3  If your understanding of A.I. and Machine Lear...  \n",
       "4  Want to learn about applied Artificial Intelli...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## doing some cleaning up\n",
    "df['text'] = df['text'].str.replace('\\n', '')\n",
    "df['text'] = df['text'].str.replace('.', '. ')\n",
    "df['text'] = df['text'].str.replace('.  ', '. ')\n",
    "df['text'] = df['text'].str.replace('?', '? ')\n",
    "df['text'] = df['text'].str.replace('!', '! ')\n",
    "df['text'] = df['text'].str.replace(':', ': ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Oh, how the headlines blared: Chatbots were The Next Big Thing. Our hopes were sky high. Bright-eyed and bushy-tailed, the industry was ripe for a new era of innovation:  it was time to start socializing with machines. And why wouldn’t they be?  All the road signs pointed towards insane success. At the Mobile World Congress 2017, chatbots were the main headliners. The conference organizers cited an ‘overwhelming acceptance at the event of the inevitable shift of focus for brands and corporates to chatbots’. In fact, the only significant question around chatbots was who would monopolize the field, not whether chatbots would take off in the first place: One year on, we have an answer to that question. No. Because there isn’t even an ecosystem for a platform to dominate. Chatbots weren’t the first technological development to be talked up in grandiose terms and then slump spectacularly. The age-old hype cycle unfolded in familiar fashion. . . Expectations built, built, and then. . . . . It all kind of fizzled out. The predicted paradim shift didn’t materialize. And apps are, tellingly, still alive and well. We look back at our breathless optimism and turn to each other, slightly baffled: “is that it?  THAT was the chatbot revolution we were promised? ”Digit’s Ethan Bloch sums up the general consensus: According to Dave Feldman, Vice President of Product Design at Heap, chatbots didn’t just take on one difficult problem and fail:  they took on several and failed all of them. Bots can interface with users in different ways. The big divide is text vs. speech. In the beginning (of computer interfaces) was the (written) word. Users had to type commands manually into a machine to get anything done. Then, graphical user interfaces (GUIs) came along and saved the day. We became entranced by windows, mouse clicks, icons. And hey, we eventually got color, too! Meanwhile, a bunch of research scientists were busily developing natural language (NL) interfaces to databases, instead of having to learn an arcane database query language. Another bunch of scientists were developing speech-processing software so that you could just speak to your computer, rather than having to type. This turned out to be a whole lot more difficult than anyone originally realised: The next item on the agenda was holding a two-way dialog with a machine. Here’s an example dialog (dating back to the 1990s) with VCR setup system: Pretty cool, right?  The system takes turns in collaborative way, and does a smart job of figuring out what the user wants. It was carefully crafted to deal with conversations involving VCRs, and could only operate within strict limitations. Modern day bots, whether they use typed or spoken input, have to face all these challenges, but also work in an efficient and scalable way on a variety of platforms. Basically, we’re still trying to achieve the same innovations we were 30 years ago. Here’s where I think we’re going wrong: An oversized assumption has been that apps are ‘over’, and would be replaced by bots. By pitting two such disparate concepts against one another (instead of seeing them as separate entities designed to serve different purposes) we discouraged bot development. You might remember a similar war cry when apps first came onto the scene ten years ago:  but do you remember when apps replaced the internet? It’s said that a new product or service needs to be two of the following:  better, cheaper, or faster. Are chatbots cheaper or faster than apps?  No — not yet, at least. Whether they’re ‘better’ is subjective, but I think it’s fair to say that today’s best bot isn’t comparable to today’s best app. Plus, nobody thinks that using Lyft is too complicated, or that it’s too hard to order food or buy a dress on an app. What is too complicated is trying to complete these tasks with a bot — and having the bot fail. A great bot can be about as useful as an average app. When it comes to rich, sophisticated, multi-layered apps, there’s no competition. That’s because machines let us access vast and complex information systems, and the early graphical information systems were a revolutionary leap forward in helping us locate those systems. Modern-day apps benefit from decades of research and experimentation. Why would we throw this away? But, if we swap the word ‘replace’ with ‘extend’, things get much more interesting. Today’s most successful bot experiences take a hybrid approach, incorporating chat into a broader strategy that encompasses more traditional elements. The next wave will be multimodal apps, where you can say what you want (like with Siri) and get back information as a map, text, or even a spoken response. Another problematic aspect of the sweeping nature of hype is that it tends to bypass essential questions like these. For plenty of companies, bots just aren’t the right solution. The past two years are littered with cases of bots being blindly applied to problems where they aren’t needed. Building a bot for the sake of it, letting it loose and hoping for the best will never end well: The vast majority of bots are built using decision-tree logic, where the bot’s canned response relies on spotting specific keywords in the user input. The advantage of this approach is that it’s pretty easy to list all the cases that they are designed to cover. And that’s precisely their disadvantage, too. That’s because these bots are purely a reflection of the capability, fastidiousness and patience of the person who created them; and how many user needs and inputs they were able to anticipate. Problems arise when life refuses to fit into those boxes. According to recent reports, 70% of the 100,000+ bots on Facebook Messenger are failing to fulfil simple user requests. This is partly a result of developers failing to narrow their bot down to one strong area of focus. When we were building GrowthBot, we decided to make it specific to sales and marketers:  not an ‘all-rounder’, despite the temptation to get overexcited about potential capabilties. Remember:  a bot that does ONE thing well is infinitely more helpful than a bot that does multiple things poorly. A competent developer can build a basic bot in minutes — but one that can hold a conversation?  That’s another story. Despite the constant hype around AI, we’re still a long way from achieving anything remotely human-like. In an ideal world, the technology known as NLP (natural language processing) should allow a chatbot to understand the messages it receives. But NLP is only just emerging from research labs and is very much in its infancy. Some platforms provide a bit of NLP, but even the best is at toddler-level capacity (for example, think about Siri understanding your words, but not their meaning. )As Matt Asay outlines, this results in another issue:  failure to capture the attention and creativity of developers. And conversations are complex. They’re not linear. Topics spin around each other, take random turns, restart or abruptly finish. Today’s rule-based dialogue systems are too brittle to deal with this kind of unpredictability, and statistical approaches using machine learning are just as limited. The level of AI required for human-like conversation just isn’t available yet. And in the meantime, there are few high-quality examples of trailblazing bots to lead the way. As Dave Feldman remarked: Once upon a time, the only way to interact with computers was by typing arcane commands to the terminal. Visual interfaces using windows, icons or a mouse were a revolution in how we manipulate informationThere’s a reasons computing moved from text-based to graphical user interfaces (GUIs). On the input side, it’s easier and faster to click than it is to type. Tapping or selecting is obviously preferable to typing out a whole sentence, even with predictive (often error-prone ) text. On the output side, the old adage that a picture is worth a thousand words is usually true. We love optical displays of information because we are highly visual creatures. It’s no accident that kids love touch screens. The pioneers who dreamt up graphical interface were inspired by cognitive psychology, the study of how the brain deals with communication. Conversational UIs are meant to replicate the way humans prefer to communicate, but they end up requiring extra cognitive effort. Essentially, we’re swapping something simple for a more-complex alternative. Sure, there are some concepts that we can only express using language (“show me all the ways of getting to a museum that give me 2000 steps but don’t take longer than 35 minutes”), but most tasks can be carried out more efficiently and intuitively with GUIs than with a conversational UI. Aiming for a human dimension in business interactions makes sense. If there’s one thing that’s broken about sales and marketing, it’s the lack of humanity:  brands hide behind ticket numbers, feedback forms, do-not-reply-emails, automated responses and gated ‘contact us’ forms. Facebook’s goal is that their bots should pass the so-called Turing Test, meaning you can’t tell whether you are talking to a bot or a human. But a bot isn’t the same as a human. It never will be. A conversation encompasses so much more than just text. Humans can read between the lines, leverage contextual information and understand double layers like sarcasm. Bots quickly forget what they’re talking about, meaning it’s a bit like conversing with someone who has little or no short-term memory. As HubSpot team pinpointed: People aren’t easily fooled, and pretending a bot is a human is guaranteed to diminish returns (not to mention the fact that you’re lying to your users). And even those rare bots that are powered by state-of-the-art NLP, and excel at processing and producing content, will fall short in comparison. And here’s the other thing. Conversational UIs are built to replicate the way humans prefer to communicate — with other humans. But is that how humans prefer to interact with machines? Not necessarily. At the end of the day, no amount of witty quips or human-like mannerisms will save a bot from conversational failure. In a way, those early-adopters weren’t entirely wrong. People are yelling at Google Home to play their favorite song, ordering pizza from the Domino’s bot and getting makeup tips from Sephora. But in terms of consumer response and developer involvement, chatbots haven’t lived up to the hype generated circa 2015/16. Not even close. Computers are good at being computers. Searching for data, crunching numbers, analyzing opinions and condensing that information. Computers aren’t good at understanding human emotion. The state of NLP means they still don’t ‘get’ what we’re asking them, never mind how we feel. That’s why it’s still impossible to imagine effective customer support, sales or marketing without the essential human touch:  empathy and emotional intelligence. For now, bots can continue to help us with automated, repetitive, low-level tasks and queries; as cogs in a larger, more complex system. And we did them, and ourselves, a disservice by expecting so much, so soon. But that’s not the whole story. Yes, our industry massively overestimated the initial impact chatbots would have. Emphasis on initial. As Bill Gates once said: The hype is over. And that’s a good thing. Now, we can start examining the middle-grounded grey area, instead of the hyper-inflated, frantic black and white zone. I believe we’re at the very beginning of explosive growth. This sense of anti-climax is completely normal for transformational technology. Messaging will continue to gain traction. Chatbots aren’t going away. NLP and AI are becoming more sophisticated every day. Developers, apps and platforms will continue to experiment with, and heavily invest in, conversational marketing. And I can’t wait to see what happens next. From a quick cheer to a standing ovation, clap to show how much you enjoyed this story. Head of Growth for GrowthBot, Messaging & Conversational Strategy @HubSpotMedium's largest publication for makers. Subscribe to receive our top stories here → https: //goo. gl/zHcLJi\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of this exercise, I will select just the first row in the df to summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>claps</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Justin Lee</td>\n",
       "      <td>8.3K</td>\n",
       "      <td>11</td>\n",
       "      <td>https://medium.com/swlh/chatbots-were-the-next...</td>\n",
       "      <td>Chatbots were the next big thing: what happene...</td>\n",
       "      <td>Oh, how the headlines blared: Chatbots were Th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       author claps  reading_time  \\\n",
       "0  Justin Lee  8.3K            11   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://medium.com/swlh/chatbots-were-the-next...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Chatbots were the next big thing: what happene...   \n",
       "\n",
       "                                                text  \n",
       "0  Oh, how the headlines blared: Chatbots were Th...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.iloc[[0]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "sentences = []\n",
    "for s in df['text']:\n",
    "  sentences.append(sent_tokenize(s))\n",
    "\n",
    "sentences = [y for x in sentences for y in x] # flatten list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Word Embeddings\n",
    "\n",
    "downloading pre-trained GloVe word embeddings (trained on Wikipedia articles) from:\n",
    "\n",
    "http://nlp.stanford.edu/data/glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract word vectors\n",
    "word_embeddings = {}\n",
    "f = open('data/glove.6B/glove.6B.100d.txt', encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    word_embeddings[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectors from 400k different terms stored in dictionary 'word_embeddings'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\RobertPagano\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# remove punctuations, numbers and special characters\n",
    "clean_sentences = pd.Series(sentences).str.replace(\"[^a-zA-Z]\", \" \")\n",
    "\n",
    "# make alphabets lowercase\n",
    "clean_sentences = [s.lower() for s in clean_sentences]\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove stopwords\n",
    "def remove_stopwords(sen):\n",
    "    sen_new = \" \".join([i for i in sen if i not in stop_words])\n",
    "    return sen_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords from the sentences\n",
    "clean_sentences = [remove_stopwords(r.split()) for r in clean_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Representation of Sentences to Summarize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_vectors = []\n",
    "for i in clean_sentences:\n",
    "  if len(i) != 0:\n",
    "    v = sum([word_embeddings.get(w, np.zeros((100,))) for w in i.split()])/(len(i.split())+0.001)/len(i.split())\n",
    "  else:\n",
    "    v = np.zeros((100,))\n",
    "  sentence_vectors.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.06382809,  0.09177911,  0.12717892,  0.06284608, -0.01834458,\n",
       "       -0.09346077,  0.19451775,  0.20676911, -0.00334608,  0.02346177,\n",
       "        0.1657896 , -0.03655922, -0.13967766,  0.05920789,  0.06758371,\n",
       "       -0.00159665,  0.07687406, -0.12206397,  0.0054083 ,  0.10788106,\n",
       "        0.17871564, -0.10188406,  0.03512993,  0.13056472, -0.14343828,\n",
       "        0.05956272,  0.15232384, -0.110997  , -0.08306597, -0.20588706,\n",
       "        0.07406547, -0.16765367,  0.03341829,  0.06630685,  0.34570214,\n",
       "       -0.07956772,  0.01941429,  0.03512494,  0.23765118,  0.01764918,\n",
       "       -0.05262369, -0.16465517, -0.03009995, -0.00084315, -0.06967766,\n",
       "        0.26414294,  0.04409545,  0.07864068,  0.06878811,  0.17954773,\n",
       "       -0.2587706 , -0.06105197,  0.109008  , -0.01011944, -0.12214893,\n",
       "        0.00391104,  0.08542229, -0.07989755,  0.02728636, -0.02134583,\n",
       "       -0.02693653, -0.09051724, -0.0926012 ,  0.02701899,  0.11056971,\n",
       "       -0.05942029, -0.03931034,  0.0248993 ,  0.15335332,  0.09356322,\n",
       "       -0.08985257, -0.00262469, -0.01082009, -0.23216891, -0.06596952,\n",
       "       -0.05467516,  0.13751874,  0.0064023 ,  0.04655922,  0.13943778,\n",
       "       -0.30752124, -0.25427288,  0.10326587, -0.06367816,  0.27371314,\n",
       "        0.17819841, -0.15935032, -0.18037481, -0.03901299,  0.05103698,\n",
       "       -0.19577211,  0.02653173, -0.01092879,  0.0378036 ,  0.19006497,\n",
       "       -0.07787606,  0.01675063, -0.02698151,  0.22220139,  0.08557471])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Matrix Preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to find the similarities between the sentences, and we'll use cosine similarity to do so. We will initiate an empty similarity matrix first, then populate it with the cosine similarities of the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity matrix\n",
    "sim_mat = np.zeros([len(clean_sentences), len(clean_sentences)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(clean_sentences)):\n",
    "  for j in range(len(clean_sentences)):\n",
    "    if i != j:\n",
    "      sim_mat[i][j] = cosine_similarity(sentence_vectors[i].reshape(1,100), sentence_vectors[j].reshape(1,100))[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying PageRank Algorithm\n",
    "\n",
    "**Note that I want to also try \"TextRank\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will convert the similarity matrix \"sim_mat\" into a graph - the nodes will represent sentences and the edges will represent similarity scores between the sentences. We will then apply the PageRank algorithm to define the sentence rankings\n",
    "\n",
    "For more info on PageRank, see here: https://en.wikipedia.org/wiki/PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "nx_graph = nx.from_numpy_array(sim_mat)\n",
    "scores = nx.pagerank(nx_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will extract the top N sentences based on their rankings for summary generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building a bot for the sake of it, letting it loose and hoping for the best will never end well: The vast majority of bots are built using decision-tree logic, where the bot’s canned response relies on spotting specific keywords in the user input.\n",
      "Some platforms provide a bit of NLP, but even the best is at toddler-level capacity (for example, think about Siri understanding your words, but not their meaning.\n",
      "This turned out to be a whole lot more difficult than anyone originally realised: The next item on the agenda was holding a two-way dialog with a machine.\n",
      "The next wave will be multimodal apps, where you can say what you want (like with Siri) and get back information as a map, text, or even a spoken response.\n",
      "The level of AI required for human-like conversation just isn’t available yet.\n"
     ]
    }
   ],
   "source": [
    "# Extract top 5 sentences as the summary\n",
    "for i in range(5):\n",
    "  print(ranked_sentences[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
